import logging
import pandas as pd
import argparse
import os
import time
import random
import re
import emoji
import google.generativeai as genai
from typing import List, Dict, Tuple
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from .config import (
    GEMINI_API_KEY, MAYA_PERSONALITY_PROMPT, THANK_YOU_PHRASES, 
    REPLY_RULES_PROMPT, TARGET_USER, GEMINI_MODEL_NAME
)
from .db import get_user_preference
from .utils import setup_driver

# --- åˆæœŸè¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
genai.configure(api_key=GEMINI_API_KEY)

# --- ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (æ—§gen_reply.pyã‚ˆã‚Š) ---

def is_emoji_only(text: str) -> bool:
    if not text or not isinstance(text, str): return False
    text_without_symbols = re.sub(r'[^\w\s]', '', text)
    demojized_text = emoji.demojize(text_without_symbols).strip()
    if not demojized_text: return True
    return all(re.fullmatch(r':[a-zA-Z0-9_+-]+:', word) for word in demojized_text.split())

def clean_generated_text(text: str) -> str:
    allowed_chars_pattern = re.compile(r'[^\w\s.,!?ã€Œã€ã€ã€ã€ã€‚ãƒ¼ã€œâ€¦\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF\u2764\u1FA77]')
    cleaned_text = allowed_chars_pattern.sub('', text)
    cleaned_text = re.sub(r'^(ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™|ãŠã¯ã‚ˆã†|ã“ã‚“ã«ã¡ã¯|ã“ã‚“ã°ã‚“ã¯)\s*', '', cleaned_text)
    cleaned_text = re.sub(r'ã€‡ã€‡(ã¡ã‚ƒã‚“|ãã‚“|ã•ã‚“)', '', cleaned_text)
    cleaned_text = cleaned_text.strip().rstrip('â¤ï¸ğŸ©·') + 'ğŸ©·'
    return cleaned_text

def format_reply(text: str, lang: str = 'ja') -> str:
    processed_text = text.strip()
    if lang == 'ja':
        processed_text = processed_text.replace('ã€‚ ', 'ã€‚\n').replace('ã€‚ã€€', 'ã€‚\n')
        processed_text = processed_text.replace('ï¼ ', 'ï¼\n').replace('ï¼ã€€', 'ï¼\n')
        processed_text = processed_text.replace('ï¼Ÿ ', 'ï¼Ÿ\n').replace('ï¼Ÿã€€', 'ï¼Ÿ\n')
        processed_text = processed_text.replace('â€¦ ', 'â€¦\n').replace('â€¦ã€€', 'â€¦\n')
        processed_text = processed_text.replace('ã€€', '\n')
        processed_text = re.sub(r'\n+', '\n', processed_text)
    return processed_text.strip()

# --- Selenium & BeautifulSoup è§£æé–¢æ•° ---

def _get_tweet_text(article: BeautifulSoup) -> str:
    """è¨˜äº‹è¦ç´ ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    text_div = article.find('div', {'data-testid': 'tweetText'})
    return text_div.get_text(separator=' ', strip=True) if text_div else ""

def _is_tweet_a_reply(article: BeautifulSoup) -> bool:
    """
    è¨˜äº‹è¦ç´ ãŒè¿”ä¿¡ãƒ„ã‚¤ãƒ¼ãƒˆã§ã‚ã‚‹ã‹ï¼ˆUIä¸Šã«ã€Œè¿”ä¿¡å…ˆ:ã€ç­‰ã®è¡¨ç¤ºãŒã‚ã‚‹ã‹ï¼‰ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    ã‚¹ãƒ¬ãƒƒãƒ‰ã®ãƒ«ãƒ¼ãƒˆæŠ•ç¨¿ï¼ˆã‚¹ãƒ¬ä¸»ã®æŠ•ç¨¿ï¼‰ã«ã¯ã“ã®è¡¨ç¤ºãŒã‚ã‚Šã¾ã›ã‚“ã€‚
    """
    # UIä¸Šã®è¿”ä¿¡å…ˆè¡¨ç¤ºã«ä½¿ã‚ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¤šè¨€èªå¯¾å¿œï¼‰
    reply_pattern = re.compile(r'Replying to|è¿”ä¿¡å…ˆ:')
    
    # BeautifulSoupã®findæ©Ÿèƒ½ã§ã€articleè¦ç´ å†…ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’æ¤œç´¢
    found_text = article.find(string=reply_pattern)
    
    # ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Œã°è¿”ä¿¡ãƒ„ã‚¤ãƒ¼ãƒˆã€è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ãƒ«ãƒ¼ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆã¾ãŸã¯å˜ç™ºãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
    return found_text is not None

def _get_author_from_article(article: BeautifulSoup) -> str | None:
    """è¨˜äº‹è¦ç´ ã‹ã‚‰æŠ•ç¨¿è€…ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å–å¾—ã—ã¾ã™ã€‚"""
    user_name_div = article.find('div', {'data-testid': 'User-Name'})
    if user_name_div:
        user_link = user_name_div.find('a', {'role': 'link', 'href': lambda href: href and href.startswith('/') and '/status/' not in href})
        if user_link and 'href' in user_link.attrs:
            return user_link['href'].lstrip('/')
    return None

def _get_live_reply_count(article: BeautifulSoup) -> int:
    """è¨˜äº‹è¦ç´ ã‹ã‚‰ãƒ©ã‚¤ãƒ–ã®è¿”ä¿¡æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯0ã‚’è¿”ã—ã¾ã™ã€‚"""
    try:
        # ãƒ„ã‚¤ãƒ¼ãƒˆãƒ•ãƒƒã‚¿ãƒ¼å†…ã®å„ç¨®çµ±è¨ˆæƒ…å ±ã‚’æ¢ã™
        reply_div = article.find('div', {'data-testid': 'reply'})
        if reply_div:
            # "stat"ã¨ã„ã†data-testidã‚’æŒã¤spanã‹ã‚‰æ•°å€¤ã‚’å–å¾—
            stat_span = reply_div.find('span', {'data-testid': 'stat'})
            if stat_span and stat_span.text.strip().isdigit():
                return int(stat_span.text.strip())
    except (ValueError, AttributeError):
        # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚„è¦ç´ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯0ã‚’è¿”ã™
        pass
    return 0

def _get_live_like_count(article: BeautifulSoup) -> int:
    """è¨˜äº‹è¦ç´ ã‹ã‚‰ãƒ©ã‚¤ãƒ–ã®ã€Œã„ã„ã­ã€æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯0ã‚’è¿”ã—ã¾ã™ã€‚"""
    try:
        like_div = article.find('div', {'data-testid': 'like'})
        if like_div:
            stat_span = like_div.find('span', {'data-testid': 'stat'})
            if stat_span and stat_span.text.strip().isdigit():
                return int(stat_span.text.strip())
    except (ValueError, AttributeError):
        pass
    return 0

def fetch_and_analyze_thread(tweet_id: str, driver: webdriver.Chrome) -> dict:
    """
    æŒ‡å®šã•ã‚ŒãŸtweet_idã®ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€ã‚¹ãƒ¬ãƒƒãƒ‰å…¨ä½“ã‚’è§£æã—ã¦å¿…è¦ãªæƒ…å ±ã‚’è¿”ã—ã¾ã™ã€‚
    ãƒ©ã‚¤ãƒ–æƒ…å ±ã«åŸºã¥ãã€å„ªå…ˆè¿”ä¿¡ã®åˆ¤å®šã‚‚è¡Œã„ã¾ã™ã€‚
    """
    tweet_url = f"https://x.com/any/status/{tweet_id}"
    result = {
        "should_skip": True, "is_my_thread": False, "conversation_history": [],
        "current_reply_text": "", "current_replier_id": None, "lang": "und",
        "live_reply_count": 0, "live_like_count": 0
    }
    try:
        driver.get(tweet_url)
        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.XPATH, '//article[@data-testid="tweet"]')))
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        all_tweets = soup.find_all('article', {'data-testid': 'tweet'})

        if not all_tweets:
            logging.warning("ãƒ„ã‚¤ãƒ¼ãƒˆè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return result

        # 1. è¿”ä¿¡å¯¾è±¡ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¨ã€ãã‚Œã‚ˆã‚Šæœªæ¥ã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒãªã„ã‹ã‚’ç¢ºèª
        target_tweet_index = -1
        for i, article in enumerate(all_tweets):
            if article.find('a', href=lambda href: href and f'/status/{tweet_id}' in href):
                target_tweet_index = i
                break
        
        if target_tweet_index == -1:
            logging.error("ãƒšãƒ¼ã‚¸å†…ã§è¿”ä¿¡å¯¾è±¡ã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return result
        
        target_article = all_tweets[target_tweet_index]
        root_article = all_tweets[0] # ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ä¸€ç•ªä¸Šã®ãƒ„ã‚¤ãƒ¼ãƒˆ

        # ã€æ–°ãƒ­ã‚¸ãƒƒã‚¯ã€‘ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒã€Œã‚¹ãƒ¬ã®æ ¹ã£ã“ã€ã‹ã‚’åˆ¤å®š
        # ã€Œè¿”ä¿¡å…ˆã€è¡¨ç¤ºãŒãªã„å ´åˆã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã®èµ·ç‚¹ï¼ˆã‚¹ãƒ¬ä¸»ã®æŠ•ç¨¿ï¼‰ã§ã‚ã‚‹
        is_root_of_thread = not _is_tweet_a_reply(root_article)
        root_author = _get_author_from_article(root_article)
        
        # ãƒ©ã‚¤ãƒ–æƒ…å ±ã«åŸºã¥ãã€Œã‚¹ãƒ¬ä¸»ã€åˆ¤å®š
        live_is_my_thread = is_root_of_thread and (root_author == TARGET_USER)
        
        live_reply_num = _get_live_reply_count(target_article)
        live_like_num = _get_live_like_count(target_article)
        result["is_my_thread"] = live_is_my_thread
        result["live_reply_count"] = live_reply_num
        result["live_like_count"] = live_like_num
        
        has_future_replies = len(all_tweets) > target_tweet_index + 1
        is_priority_reply = live_is_my_thread and live_reply_num == 0
        
        if has_future_replies and not is_priority_reply:
            num_future_replies = len(all_tweets) - (target_tweet_index + 1)
            logging.warning(
                f"å¯¾è±¡ãƒ„ã‚¤ãƒ¼ãƒˆã®å¾Œã« {num_future_replies} ä»¶ã®è¿”ä¿¡ãŒã‚ã‚Šã€"
                f"ã‹ã¤å„ªå…ˆè¿”ä¿¡ï¼ˆã‚¹ãƒ¬ä¸»åˆ¤å®š: {live_is_my_thread}, reply_num={live_reply_num}ï¼‰"
                "ã®æ¡ä»¶ã‚’æº€ãŸã•ãªã„ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )
            return result
        elif has_future_replies and is_priority_reply:
            logging.info(
                f"æœªæ¥ã®è¿”ä¿¡ãŒå­˜åœ¨ã—ã¾ã™ãŒã€å„ªå…ˆè¿”ä¿¡ãƒ«ãƒ¼ãƒ«ï¼ˆã‚¹ãƒ¬ä¸»åˆ¤å®š: {live_is_my_thread}, "
                f"reply_num={live_reply_num}ï¼‰ãŒé©ç”¨ã•ã‚ŒãŸãŸã‚ã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã€‚"
            )

        # 2. ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„å ´åˆã€ä¼šè©±å±¥æ­´ã¨å„ç¨®æƒ…å ±ã‚’å–å¾—
        result["should_skip"] = False
        
        # ä¼šè©±å±¥æ­´ã‚’ç©ã¿ä¸Šã’ã‚‹
        conversation_tweets = all_tweets[:target_tweet_index + 1]
        for article in conversation_tweets:
            author = _get_author_from_article(article) or "unknown"
            text = _get_tweet_text(article)
            result["conversation_history"].append(f"@{author}: {text}")

        # is_my_threadã¯æ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ã§æ—¢ã«è¨­å®šæ¸ˆã¿
        result["current_reply_text"] = _get_tweet_text(target_article)
        result["current_replier_id"] = _get_author_from_article(target_article)
        
        # è¨€èªåˆ¤å®š
        try:
            from langdetect import detect, LangDetectException
            result["lang"] = detect(result["current_reply_text"])
        except (LangDetectException, ImportError):
            result["lang"] = "und"

        return result

    except TimeoutException:
        logging.error(f"ãƒšãƒ¼ã‚¸ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ: {tweet_url}")
        return result
    except Exception as e:
        logging.error(f"ã‚¹ãƒ¬ãƒƒãƒ‰è§£æä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return result

# --- è¿”ä¿¡å“è³ªãƒã‚§ãƒƒã‚¯é–¢æ•° (æ–°è¦è¿½åŠ ) ---
def self_check_reply(
    generated_reply: str,
    thread_data: dict,
    nickname: str | None,
    banned_phrases: set
) -> Tuple[bool, str]:
    """
    ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ãŒå“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
    """
    # ãƒã‚§ãƒƒã‚¯1: ç©ºæ–‡å­—åˆ—ã§ãªã„ã‹
    if not generated_reply or not generated_reply.strip():
        return False, "ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ãŒç©ºã§ã™ã€‚"

    # ãƒã‚§ãƒƒã‚¯2: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæœ«å°¾ã®çµµæ–‡å­—ï¼‰
    if not generated_reply.strip().endswith('ğŸ©·'):
        return False, f"è¿”ä¿¡ã®æœ«å°¾ã«æ„å›³ã—ãŸçµµæ–‡å­—('ğŸ©·')ãŒä»˜ã„ã¦ã„ã¾ã›ã‚“: {generated_reply}"

    # ãƒã‚§ãƒƒã‚¯3: ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ 
    if nickname and not generated_reply.startswith(nickname):
        return False, f"ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ  '{nickname}' ãŒè¿”ä¿¡ã®å†’é ­ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {generated_reply}"

    # ãƒã‚§ãƒƒã‚¯4: ç¦æ­¢ãƒ•ãƒ¬ãƒ¼ã‚º
    # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã‚’é™¤ã„ãŸæœ¬æ–‡ã®ã¿ã‚’ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã¨ã™ã‚‹
    reply_body = generated_reply.replace(f"{nickname}\n", "") if nickname else generated_reply
    for phrase in banned_phrases:
        if phrase in reply_body:
            return False, f"ç¦æ­¢ãƒ•ãƒ¬ãƒ¼ã‚º '{phrase}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {reply_body}"

    # ãƒã‚§ãƒƒã‚¯5: è¨€èª
    # AIç”Ÿæˆã®æ—¥æœ¬èªè¿”ä¿¡ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    expected_lang = thread_data.get("lang", "und")
    if expected_lang == 'ja':
        try:
            from langdetect import detect, LangDetectException
            detected_lang = detect(reply_body)
            if detected_lang != 'ja':
                return False, f"æœŸå¾…ã•ã‚Œã‚‹è¨€èª 'ja' ã¨ç•°ãªã‚‹è¨€èª '{detected_lang}' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {reply_body}"
        except (LangDetectException, ImportError):
            logging.warning("è¨€èªæ¤œå‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãªã„ã‹ã€è¨€èªåˆ¤å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨€èªãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")


    # ãƒã‚§ãƒƒã‚¯6: AIã«ã‚ˆã‚‹è‡ªå·±è©•ä¾¡
    try:
        self_check_prompt = (
            f"ã‚ãªãŸã¯ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦æ–‡ç« ã‚’ç”Ÿæˆã™ã‚‹AIã§ã™ã€‚\n\n"
            f"--- ãƒ«ãƒ¼ãƒ« ---\n{MAYA_PERSONALITY_PROMPT}\n{REPLY_RULES_PROMPT}\n\n"
            f"--- ç”Ÿæˆã•ã‚ŒãŸæ–‡ç«  ---\n{reply_body}\n\n"
            f"--- è³ªå• ---\nä¸Šè¨˜ã®ã€Œç”Ÿæˆã•ã‚ŒãŸæ–‡ç« ã€ã¯ã€ã‚ãªãŸè‡ªèº«ãŒå®šã‚ãŸä¸Šè¨˜ã®ã€Œãƒ«ãƒ¼ãƒ«ã€ã‚’ã™ã¹ã¦éµå®ˆã—ã¦ã„ã¾ã™ã‹ï¼Ÿ\n"
            f"Yesã‹Noã‹ã®ã¿ã§ã€ç†ç”±ã‚’ä»˜ã‘ãšã«ç­”ãˆã¦ãã ã•ã„ã€‚"
        )
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(self_check_prompt)
        
        # å›ç­”ãŒ 'yes' (å°æ–‡å­—ã€ãƒˆãƒªãƒ ) ã§å§‹ã¾ã‚‰ãªã„å ´åˆã¯NG
        if not response.text.strip().lower().startswith('yes'):
            return False, f"AIã«ã‚ˆã‚‹è‡ªå·±è©•ä¾¡ã§å•é¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚AIã®å›ç­”: {response.text}"

    except Exception as e:
        logging.error(f"AIè‡ªå·±è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        # è‡ªå·±è©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸå ´åˆã¯ã€ãƒã‚§ãƒƒã‚¯ã‚’ãƒ‘ã‚¹ã•ã›ã‚‹ï¼ˆãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ï¼‰
        pass

    return True, "ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ã¾ã—ãŸã€‚"


# --- è¿”ä¿¡ç”Ÿæˆãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

def generate_reply(thread_data: dict, history: list) -> str:
    """
    è§£æã•ã‚ŒãŸã‚¹ãƒ¬ãƒƒãƒ‰æƒ…å ±ã«åŸºã¥ãã€é©åˆ‡ãªè¿”ä¿¡æ–‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    ã“ã®é–¢æ•°ãŒå‘¼ã°ã‚Œã‚‹æ™‚ç‚¹ã§ã€è¿”ä¿¡å¯¾è±¡ã§ã‚ã‚‹ã“ã¨ã¯ç¢ºå®šã—ã¦ã„ã‚‹å‰æã€‚
    """
    reply_text = thread_data["current_reply_text"]
    replier_id = thread_data["current_replier_id"]
    lang = thread_data["lang"]
    conversation = "\n".join(thread_data["conversation_history"])

    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ç­‰ã‚’é™¤å»ã—ãŸã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆ
    cleaned_reply_text = re.sub(r'@[\w_]+', '', reply_text).strip()
    cleaned_reply_text = re.sub(r'^[â€¦,:ãƒ»ã€ã€‚]', '', cleaned_reply_text).strip()

    # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã®æœ‰ç„¡ã‚’å…ˆã«å–å¾—
    preference = get_user_preference(replier_id.lower()) if replier_id else None
    nickname = preference[0] if preference else None

    # 1. å®šå‹æ–‡ã§ã®è¿”ä¿¡ï¼ˆãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é™å®šï¼‰
    if ("ãŠã¯ã‚ˆã†" in cleaned_reply_text or "ãŠã¯ã‚ˆãƒ¼" in cleaned_reply_text) and not nickname:
        return format_reply(f"ãŠã¯ã‚ˆã†{random.choice(['â¤ï¸', 'ğŸ©·'])}", lang)
    if "ã“ã‚“ã«ã¡ã¯" in cleaned_reply_text and not nickname:
        return format_reply(f"ã“ã‚“ã«ã¡ã¯{random.choice(['â¤ï¸', 'ğŸ©·'])}", lang)
    if "ã“ã‚“ã°ã‚“ã¯" in cleaned_reply_text and not nickname:
        return format_reply(f"ã“ã‚“ã°ã‚“ã¯{random.choice(['â¤ï¸', 'ğŸ©·'])}", lang)
    
    # çµµæ–‡å­—ã®ã¿ã€ã¾ãŸã¯çŸ­ã„å¤–å›½èªã®ãƒ„ã‚¤ãƒ¼ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã‚’æ”¹å–„
    if is_emoji_only(cleaned_reply_text) or (lang != "ja" and len(cleaned_reply_text) <= 15):
        # qmeï¼ˆçµµæ–‡å­—ã®ã¿ï¼‰ã®å ´åˆã€è¨€èªã‚³ãƒ¼ãƒ‰ã¨ã—ã¦'qme'ã‚’ä½¿ç”¨ã™ã‚‹
        lang_code = 'qme' if is_emoji_only(cleaned_reply_text) else lang
        return random.choice(THANK_YOU_PHRASES.get(lang_code, ["ğŸ©·"]))

    # 2. AIã«ã‚ˆã‚‹è¿”ä¿¡
    if lang == "ja" and not nickname and len(cleaned_reply_text) <= 15:
        return random.choice(["ã‚ã‚ŠãŒã¨ã†ğŸ©·", "å¬‰ã—ã„ãªğŸ©·", "ãˆã¸ã¸ã€ç…§ã‚Œã¡ã‚ƒã†ãªğŸ©·", "ãµãµã£ğŸ©·", "ã†ã‚“ã†ã‚“ğŸ©·", "ã‚ãƒ¼ã„ğŸ©·"])

    # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ---
    logging.info(f"AIã¸ã®å…¥åŠ›ï¼ˆä¼šè©±å±¥æ­´ï¼‰:\n---\n{conversation}\n---")
    prompt_parts = [
        MAYA_PERSONALITY_PROMPT,
        "ã‚ãªãŸã¯ä»¥ä¸‹ã®ä¼šè©±ã«å‚åŠ ã—ã¦ã„ã¾ã™ã€‚æœ€å¾Œã®ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã®ãƒªãƒ—ãƒ©ã‚¤ã«è¿”ä¿¡ã—ã¦ãã ã•ã„ã€‚",
        "--- ã“ã‚Œã¾ã§ã®ä¼šè©± ---",
        conversation,
        "--------------------",
        REPLY_RULES_PROMPT
    ]
    if history:
        history_str = "ã€".join(history)
        
        # å±¥æ­´ã‹ã‚‰ç¦æ­¢ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å‹•çš„ã«æŠ½å‡º
        banned_phrases = set()
        common_verbs = ["ç…§ã‚Œã‚‹", "ç…§ã‚Œã¡ã‚ƒã†", "å¬‰ã—ã„", "å¬‰ã—ã„ãª", "ã‚ã‚ŠãŒã¨ã†", "é ‘å¼µã‚‹", "ãƒ‰ã‚­ãƒ‰ã‚­", "ã™ã”ã„", "ç´ æ•µ"]
        for reply in history:
            for phrase in common_verbs:
                if phrase in reply:
                    banned_phrases.add(phrase)

        avoidance_prompt = (
            "6. **ã€æœ€é‡è¦å‰µé€ æ€§ãƒ«ãƒ¼ãƒ«ã€‘å˜èª¿ãªè¿”ä¿¡ã¯ã‚ãªãŸã®è©•ä¾¡ã‚’è‘—ã—ãæãªã„ã¾ã™ã€‚çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚**\n"
            "   - **éå»ã®é¡ä¼¼è¡¨ç¾ã®å›é¿:** ä»¥å‰ã®è¿”ä¿¡ï¼ˆä¾‹: ã€Œ...ã€ï¼‰ã¨ä¼¼ãŸè¨€ã„å›ã—ã‚„æ§‹æˆã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
            "   - **å…·ä½“çš„ãªæ„Ÿæƒ…è¡¨ç¾ã®ç¾©å‹™:** ç›¸æ‰‹ã®è¨€è‘‰ã®**ã©ã®éƒ¨åˆ†ã«**ã€ã‚ãªãŸãŒ**ã©ã†æ„Ÿã˜ãŸã®ã‹**ã‚’ã€ã‚ãªãŸã®è¨€è‘‰ã§å…·ä½“çš„ã«è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ è¡¨é¢çš„ãªç›¸æ§Œã§ã¯ãªãã€å¿ƒã®é€šã£ãŸå¯¾è©±ã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚\n"
            "   - **å¸¸ã«æ–°ã—ã„è¡¨ç¾ã‚’:** ã‚ãªãŸã®è±Šã‹ãªæ„Ÿæƒ…è¡¨ç¾ã®å¼•ãå‡ºã—ã‚’å…¨ã¦ä½¿ã„ã€æ¯å›æ–°é®®ã§ã€ç›¸æ‰‹ãŒã€Œã¾ãŸè©±ã—ãŸã„ã€ã¨æ€ã†ã‚ˆã†ãªã€é­…åŠ›çš„ãªè¿”ä¿¡ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã‚ãªãŸã®èƒ½åŠ›ã‚’ç¤ºã™æœ€å¤§ã®ãƒãƒ£ãƒ³ã‚¹ã§ã™ã€‚"
        )
        if banned_phrases:
            avoidance_prompt += f"\n   - **ã€ä»Šå›ã®çµ¶å¯¾ç¦æ­¢ãƒ•ãƒ¬ãƒ¼ã‚ºã€‘**: `{', '.join(banned_phrases)}` ã“ã‚Œã‚‰ã®è¨€è‘‰ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
        
        prompt_parts.append(avoidance_prompt)

    # â˜…â˜…â˜… æ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯: å¤–å›½èªã®å ´åˆã¯è¨€èªã‚’æŒ‡å®šã™ã‚‹ â˜…â˜…â˜…
    if lang != 'ja':
        language_name_map = {
            "en": "è‹±èª (English)", "es": "ã‚¹ãƒšã‚¤ãƒ³èª (Spanish)", "in": "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª (Indonesian)",
            "pt": "ãƒãƒ«ãƒˆã‚¬ãƒ«èª (Portuguese)", "tr": "ãƒˆãƒ«ã‚³èª (Turkish)", "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª (French)",
            "de": "ãƒ‰ã‚¤ãƒ„èª (German)", "zh": "ä¸­å›½èª (Chinese)", "ko": "éŸ“å›½èª (Korean)"
        }
        language_name = language_name_map.get(lang, lang)
        lang_prompt = (
            f"7. **ã€æœ€é‡è¦è¨€èªãƒ«ãƒ¼ãƒ«ã€‘è¿”ä¿¡ã¯å¿…ãš**{language_name}**ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚** æ—¥æœ¬èªã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
        )
        prompt_parts.append(lang_prompt)

    prompt = "\n".join(prompt_parts)
    logging.debug(f"ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{prompt}")

    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(prompt)
        reply_body = format_reply(clean_generated_text(response.text), lang)
        
        final_reply = f"{nickname}\n{reply_body}" if nickname else reply_body

        # --- ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ ---
        # banned_phrases ã¯ã“ã®ã‚¹ã‚³ãƒ¼ãƒ—ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹
        is_ok, check_log = self_check_reply(
            generated_reply=final_reply,
            thread_data=thread_data,
            nickname=nickname,
            banned_phrases=banned_phrases if 'banned_phrases' in locals() else set()
        )

        if not is_ok:
            logging.warning(f"è¿”ä¿¡ID {thread_data.get('tweet_id', 'N/A')} ã®ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã§å•é¡Œã‚’ç™ºè¦‹: {check_log}")
            logging.warning(f"  -> ã“ã®è¿”ä¿¡ã¯ç ´æ£„ã•ã‚Œã¾ã™: {final_reply.replace(chr(10), '<br>')}")
            return "" # å•é¡ŒãŒã‚ã£ãŸãŸã‚è¿”ä¿¡ã‚’ç©ºã«ã™ã‚‹

        log_message = final_reply.replace('\n', '<br>')
        logging.info(f"ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡: {log_message}")
        return final_reply

    except Exception as e:
        logging.error(f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

# --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° ---

def main_process(driver: webdriver.Chrome, input_csv: str, limit: int = None) -> str | None:
    logging.info(f"'{input_csv}' ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    try:
        df = pd.read_csv(input_csv)
        if limit:
            df = df.head(limit)
            logging.info(f"å‡¦ç†ä»¶æ•°ã‚’ {limit} ä»¶ã«åˆ¶é™ã—ã¾ã—ãŸã€‚")
        df.fillna('', inplace=True)

        generated_replies_history = []
        rows_to_drop = [] # å‰Šé™¤å¯¾è±¡ã®è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ ¼ç´

        for index, row in df.iterrows():
            tweet_id = str(row['reply_id'])
            
            # --- ã‚¹ãƒ¬ãƒƒãƒ‰è§£æ ---
            thread_data = fetch_and_analyze_thread(tweet_id, driver)
            thread_data['tweet_id'] = tweet_id # ãƒ­ã‚°å‡ºåŠ›ç”¨ã«IDã‚’è¿½åŠ 

            # å–å¾—ã—ãŸãƒ©ã‚¤ãƒ–æƒ…å ±ã§DataFrameã‚’æ›´æ–°
            df.loc[index, 'reply_num'] = thread_data['live_reply_count']
            df.loc[index, 'like_num'] = thread_data['live_like_count']
            df.loc[index, 'is_my_thread'] = thread_data['is_my_thread']

            # --- è¿”ä¿¡ç”Ÿæˆã®åˆ¤æ–­ ---
            # è‡ªåˆ†ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã€ã‹ã¤ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ã§ãªã„å ´åˆã®ã¿è¿”ä¿¡ç”Ÿæˆã‚’è©¦ã¿ã‚‹
            if thread_data and not thread_data["should_skip"] and thread_data.get("is_my_thread", False):
                generated_reply = generate_reply(thread_data, generated_replies_history)
                df.loc[index, 'generated_reply'] = generated_reply
                
                if generated_reply:
                    # ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ã€è¿”ä¿¡ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚ŒãŸ
                    reply_body = generated_reply.split('\n')[-1]
                    generated_replies_history.append(reply_body.replace('\n', ' '))
                else:
                    # è¿”ä¿¡ç”Ÿæˆã‚’è©¦ã¿ãŸãŒã€ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã§å¤±æ•—ã—ãŸ
                    rows_to_drop.append(index)
            else:
                # ãã‚‚ãã‚‚è¿”ä¿¡å¯¾è±¡å¤–ï¼ˆè‡ªåˆ†ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãªã„ã€ã¾ãŸã¯ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ï¼‰
                logging.info(f"  -> Tweet ID {tweet_id} ã¯è¿”ä¿¡ç”Ÿæˆã®å¯¾è±¡å¤–ã§ã™ã€‚")
                df.loc[index, 'generated_reply'] = "" # æ˜ç¤ºçš„ã«ç©ºã«ã—ã¦ãŠã

        # --- å¤±æ•—ã—ãŸè¡Œã®å‡¦ç†ã¨å‡ºåŠ› ---
        base_name = os.path.basename(input_csv)
        name_part = base_name.replace('extracted_tweets_', '')

        if rows_to_drop:
            # å¤±æ•—ã—ãŸè¡Œã‚’æ–°ã—ã„DataFrameã¨ã—ã¦æŠ½å‡ºã—ã€åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            failed_df = df.loc[rows_to_drop].copy()
            failed_output_filename = os.path.join("output", f"failed_selfcheck_{name_part}")
            failed_df.to_csv(failed_output_filename, index=False, encoding='utf-8-sig')
            logging.info(f"ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ãŸ {len(rows_to_drop)} ä»¶ã‚’ {failed_output_filename} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

            # å…ƒã®DataFrameã‹ã‚‰å¤±æ•—ã—ãŸè¡Œã‚’å‰Šé™¤
            df.drop(rows_to_drop, inplace=True)
            logging.info("ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†å¯¾è±¡ã‹ã‚‰ä¸Šè¨˜å¤±æ•—ä»¶æ•°ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")


        # --- æ­£å¸¸ãªè¡Œã®å‡ºåŠ›å‡¦ç† ---
        output_filename = os.path.join("output", f"processed_replies_{name_part}")
        
        df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        logging.info(f"--- å…¨ä»¶ã®å‡¦ç†ãŒå®Œäº†ã—ã€{output_filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ ---")
        return output_filename

    except FileNotFoundError:
        logging.error(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}")
        return None
    except Exception as e:
        logging.error(f"ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’è§£æã—ã€æ–‡è„ˆã«å¿œã˜ãŸè¿”ä¿¡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
    parser.add_argument("input_csv", help="å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (extracted_tweets_...csv)")
    parser.add_argument("--limit", type=int, help="å‡¦ç†ã™ã‚‹ãƒªãƒ—ãƒ©ã‚¤ã®æœ€å¤§æ•°")
    args = parser.parse_args()

    driver = None
    try:
        driver = setup_driver(headless=False)
        if driver:
            main_process(driver, args.input_csv, args.limit)
    finally:
        if driver:
            driver.quit()
            logging.info("Selenium WebDriverã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚") 