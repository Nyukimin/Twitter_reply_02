import google.generativeai as genai
import random
import pandas as pd
import argparse
import os
import logging
import emoji
import re
from langdetect import detect, LangDetectException
from .config import GEMINI_API_KEY, MAYA_PERSONALITY_PROMPT, THANK_YOU_PHRASES
from .db import get_user_preference
from . import utils, db

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Gemini APIã‚­ãƒ¼ã‚’è¨­å®š
genai.configure(api_key=GEMINI_API_KEY)

def is_emoji_only(text: str) -> bool:
    """
    æ–‡å­—åˆ—ãŒçµµæ–‡å­—ã€ç©ºç™½ã€å¥èª­ç‚¹ã®ã¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    """
    if not text or not isinstance(text, str):
        return False
    # çµµæ–‡å­—ã€å¥èª­ç‚¹ã€ç©ºç™½ä»¥å¤–ã®æ–‡å­—ã‚’ã™ã¹ã¦å–ã‚Šé™¤ã
    text_without_symbols = re.sub(r'[^\w\s]', '', text) # ã¾ãšå¥èª­ç‚¹ã‚’å‰Šé™¤
    demojized_text = emoji.demojize(text_without_symbols).strip()

    # æ®‹ã£ãŸæ–‡å­—åˆ—ãŒç©ºã‹ã€ã‚³ãƒ­ãƒ³ã§å›²ã¾ã‚ŒãŸçµµæ–‡å­—ã‚³ãƒ¼ãƒ‰ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯
    if not demojized_text:
        return True
    
    return all(re.fullmatch(r':[a-zA-Z0-9_+-]+:', word) for word in demojized_text.split())

def detect_language(text: str) -> str:
    """
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªã‚’åˆ¤å®šã—ã¾ã™ã€‚
    """
    if not text or not text.strip():
        return "und"  # Undetermined
    try:
        # ä¿¡é ¼æ€§ãŒä½ã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã¯æ³¨æ„ãŒå¿…è¦
        return detect(text)
    except LangDetectException:
        # logging.warning(f"è¨€èªã®æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {text}")
        return "und"  # Undetermined

def format_reply(text: str) -> str:
    """
    AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚„å›ºå®šãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ•´å½¢ã—ã€æœ€çµ‚çš„ãªè¿”ä¿¡æ–‡å­—åˆ—ã‚’ä½œæˆã™ã‚‹ã€‚
    - ä¸è¦ãªç©ºç™½ã‚’æ”¹è¡Œã«å¤‰æ›ã™ã‚‹
    - çµµæ–‡å­—ã‚’ä»˜ä¸ã™ã‚‹
    - å‰å¾Œã®ç©ºç™½ã‚’é™¤å»ã™ã‚‹
    """
    # 1. å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
    processed_text = text.strip()

    # 2. å¥èª­ç‚¹ã®å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ”¹è¡Œã«ç½®æ›
    processed_text = processed_text.replace('ã€‚ ', 'ã€‚\n').replace('ã€‚ã€€', 'ã€‚\n')
    processed_text = processed_text.replace('ï¼ ', 'ï¼\n').replace('ï¼ã€€', 'ï¼\n')
    processed_text = processed_text.replace('ï¼Ÿ ', 'ï¼Ÿ\n').replace('ï¼Ÿã€€', 'ï¼Ÿ\n')
    processed_text = processed_text.replace('â€¦ ', 'â€¦\n').replace('â€¦ã€€', 'â€¦\n')

    # 3. å…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚æ”¹è¡Œã«å¤‰æ›ã™ã‚‹
    processed_text = processed_text.replace('ã€€', '\n')
    processed_text = processed_text.replace(' ', '\n')

    # 4. è¤‡æ•°ã®æ”¹è¡Œã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
    processed_text = re.sub(r'\n+', '\n', processed_text)

    # 5. å…¨ä½“ã®æœ«å°¾ã®ç©ºç™½ãƒ»æ”¹è¡Œã‚’ãã‚Œã„ã«ã™ã‚‹
    final_reply = processed_text.strip()

    return final_reply

def clean_generated_text(text: str) -> str:
    """
    AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹å¾Œå‡¦ç†é–¢æ•°ã€‚
    - è¨±å¯ã•ã‚Œã¦ã„ãªã„çµµæ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    - æŒ¨æ‹¶ã‚„ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    - æœ«å°¾ã®ãƒãƒ¼ãƒˆã‚’ãƒ«ãƒ¼ãƒ«é€šã‚Šã«æ•´å½¢ã™ã‚‹ã€‚
    """
    # è¨±å¯ã™ã‚‹æ–‡å­—ï¼ˆæ—¥æœ¬èªã€è‹±æ•°å­—ã€åŸºæœ¬çš„ãªè¨˜å·ã€æŒ‡å®šã®çµµæ–‡å­—ï¼‰ä»¥å¤–ã‚’å‰Šé™¤
    # U+2764ã¯â¤ï¸ã€U+1FA77ã¯ğŸ©·
    allowed_chars_pattern = re.compile(
        r'[^\w\s.,!?ã€Œã€ã€ã€ã€ã€‚ãƒ¼ã€œâ€¦\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF\u2764\u1FA77]'
    )
    cleaned_text = allowed_chars_pattern.sub('', text)

    # å†’é ­ã®æŒ¨æ‹¶ã‚’å‰Šé™¤
    cleaned_text = re.sub(r'^(ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™|ãŠã¯ã‚ˆã†|ã“ã‚“ã«ã¡ã¯|ã“ã‚“ã°ã‚“ã¯)\s*', '', cleaned_text)

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã€Œã€‡ã€‡ã¡ã‚ƒã‚“ã€ãªã©ã‚’å‰Šé™¤
    cleaned_text = re.sub(r'ã€‡ã€‡(ã¡ã‚ƒã‚“|ãã‚“|ã•ã‚“)', '', cleaned_text)
    
    # å‰å¾Œã®ç©ºç™½ã‚’ãƒˆãƒªãƒ 
    cleaned_text = cleaned_text.strip()

    # æœ«å°¾ã®ãƒãƒ¼ãƒˆã‚’ä¸€æ—¦ã™ã¹ã¦å‰Šé™¤
    cleaned_text = cleaned_text.rstrip('â¤ï¸ğŸ©·')

    # æœ«å°¾ã«ğŸ©·ã‚’1ã¤ã ã‘è¿½åŠ 
    cleaned_text += 'ğŸ©·'

    return cleaned_text

def generate_reply_for_row(row: pd.Series, original_tweet_content: str = None) -> str:
    """
    DataFrameã®è¡Œãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€AIãŒç”Ÿæˆã—ãŸå¿œç­”æ–‡ã‚’è¿”ã—ã¾ã™ã€‚
    
    Args:
        row (pd.Series): è¿”ä¿¡ã‚’ç”Ÿæˆã™ã‚‹å¯¾è±¡ã®ãƒªãƒ—ãƒ©ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¡Œã€‚
        original_tweet_content (str): Mayaã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”æ–‡ã€‚
    """
    reply_text = row['contents']
    replier_id = row['UserID']
    lang = row.get('lang', 'und') # langåˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã«å‚™ãˆã‚‹

    # AIã«æ¸¡ã™å‰ã«ã€ãƒªãƒ—ãƒ©ã‚¤æœ¬æ–‡ã‹ã‚‰ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆ@ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼‰ã‚’ã™ã¹ã¦é™¤å»ã™ã‚‹
    cleaned_reply_text = re.sub(r'@[\w_]+', '', reply_text).strip()

    # ãƒªãƒ—ãƒ©ã‚¤ãŒçµµæ–‡å­—ã®ã¿ã®å ´åˆã®å‡¦ç†
    if is_emoji_only(cleaned_reply_text):
        logging.info(f"ãƒªãƒ—ãƒ©ã‚¤ã¯çµµæ–‡å­—ã®ã¿ã§ã™ (è¨€èª: {lang})ã€‚å›ºå®šã®æ„Ÿè¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚")
        # è¨€èªã«å¯¾å¿œã™ã‚‹æ„Ÿè¬ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        thank_you_list = THANK_YOU_PHRASES.get(lang, THANK_YOU_PHRASES.get("und"))
        if thank_you_list and isinstance(thank_you_list, list):
            reply = random.choice(thank_you_list)
            return format_reply(reply)
        else: # ä¸‡ãŒä¸€ã€è©²å½“ã™ã‚‹ã‚­ãƒ¼ãŒãªã‹ã£ãŸå ´åˆã‚„ãƒªã‚¹ãƒˆã§ãªã„å ´åˆ
            return "â¤ï¸"

    # jaä»¥å¤–ã®è¨€èªã®å ´åˆã€å›ºå®šã®ã€Œã‚ã‚ŠãŒã¨ã†ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ (çµµæ–‡å­—ã®ã¿ã§ãªã„å ´åˆ)
    if lang != "ja":
        if lang in THANK_YOU_PHRASES and isinstance(THANK_YOU_PHRASES[lang], list):
            reply = random.choice(THANK_YOU_PHRASES[lang])
            return format_reply(reply)
        else:
            return "â¤ï¸"

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã‚’å–å¾—
    if replier_id:
        preference = get_user_preference(replier_id.lower())
        if preference:
            nickname = preference[0]  # nicknameã¯ã‚¿ãƒ—ãƒ«ã®æœ€åˆã®è¦ç´ 
            logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã€Œ{nickname}ã€ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        else:
            nickname = None
            logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        nickname = None
        logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    original_tweet_content = row.get('original_tweet_content', '')
    cleaned_reply_text = re.sub(r'@[\w_]+', '', reply_text).strip()
    
    # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ·æ–° ---
    prompt_parts = [
        MAYA_PERSONALITY_PROMPT,
        "ã“ã‚Œã‹ã‚‰ã€ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã®ãƒªãƒ—ãƒ©ã‚¤ãŒæç¤ºã•ã‚Œã¾ã™ã€‚",
        f'ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ï¼šã€Œ{cleaned_reply_text}ã€'
    ]
    if original_tweet_content:
        prompt_parts.append(f'ã‚ãªãŸã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼šã€Œ{original_tweet_content}ã€')

    # AIã¸ã®æŒ‡ç¤ºã‚’æ˜ç¢ºåŒ–
    prompt_parts.extend([
        "ã€è¿”ä¿¡æ–‡ã®ä½œæˆãƒ«ãƒ¼ãƒ«ã€‘",
        "1. ä¸Šè¨˜ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ã«å¯¾ã—ã¦ã€ã‚ãªãŸã®ã€Œè¿”ä¿¡ã®æœ¬æ–‡ã€ã ã‘ã‚’ã€ä¸€è¨€ã¾ãŸã¯ã”ãçŸ­ã„1æ–‡ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
        "2. **é‡è¦ï¼šç›¸æ‰‹ã®åå‰ï¼ˆã€‡ã€‡ã•ã‚“ï¼‰ã‚„ã€ã‚ãªãŸè‡ªèº«ã®åå‰ï¼ˆMayaï¼‰ã€æŒ¨æ‹¶ï¼ˆã“ã‚“ã«ã¡ã¯ã€ãªã©ï¼‰ã¯çµ¶å¯¾ã«å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚** ã“ã‚Œã‚‰ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè‡ªå‹•ã§å¯¾å¿œã™ã‚‹ãŸã‚ã€ã‚ãªãŸã®å½¹å‰²ã¯è¿”ä¿¡ã®ã€Œæœ¬æ–‡ã€ä½œæˆã®ã¿ã§ã™ã€‚",
        "3. è¿”ä¿¡ã®èªå°¾ã«ã¯ã€â¤ï¸ã‹ğŸ©·ã®ã©ã¡ã‚‰ã‹ä¸€ã¤ã‚’å¿…ãšä»˜ã‘ã¦ãã ã•ã„ã€‚æ–‡ä¸­ã‚„èªå°¾ã«ä»–ã®çµµæ–‡å­—ã¯ä¸€åˆ‡å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚",
        "4. ç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤ã«æ€§çš„ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å›°æƒ‘ã—ãŸã‚Šã€æ¥ãšã‹ã—ãŒã‚‹ã‚ˆã†ãªåå¿œã‚’ã—ã¦ãã ã•ã„ã€‚æ±ºã—ã¦å–œã‚“ã ã‚ŠåŒæ„ã—ãŸã‚Šã—ãªã„ã§ãã ã•ã„ã€‚",
        "   ï¼ˆé©åˆ‡ãªè¿”ç­”ã®ä¾‹ï¼šã€Œãˆã£ã€ãªã€ä½•è¨€ã£ã¦ã‚‹ã®â€¦ï¼Ÿâ¤ï¸ã€ã€Œã‚‚ã†ã€å†—è«‡ã°ã£ã‹ã‚Šâ€¦ğŸ©·ã€ã€Œãã†ã„ã†ã®ã¯æ¥ãšã‹ã—ã„ã‚ˆã‰â€¦ğŸ©·ã€ã€Œå¿ƒè‡“ã«æ‚ªã„ã£ã¦ã°â€¦ï¼â¤ï¸ã€ã€Œãã‚“ãªã“ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ã©ã†ã—ãŸã‚‰ã„ã„ã‹åˆ†ã‹ã‚“ãªã„ã‚ˆã‰â€¦ğŸ©·ã€ï¼‰"
    ])

    prompt = "\n".join(prompt_parts)
    logging.debug(f"ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{prompt}")

    try:
        # Gemini APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”æ–‡ã‚’ç”Ÿæˆ
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)

        # AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¾Œå‡¦ç†ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã€ãã®å¾Œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹
        raw_text = response.text
        cleaned_text = clean_generated_text(raw_text)
        reply_body = format_reply(cleaned_text)

        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯ã€æ–‡é ­ã«ã€Œãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ï¼‹æ”¹è¡Œã€ã‚’ä»˜ä¸ã™ã‚‹
        if nickname:
            final_reply = f"{nickname}\n{reply_body}"
            log_message = final_reply.replace('\n', '<br>')
            logging.info(f"ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ï¼ˆãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ä»˜ãï¼‰: {log_message}")
            return final_reply
        else:
            # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒãªã„å ´åˆã¯ã€æ•´å½¢ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
            log_message = reply_body.replace('\n', '<br>')
            logging.info(f"ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡: {log_message}")
            return reply_body

    except Exception as e:
        logging.error(f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

    return None


def main_process(input_csv: str, limit: int = None):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚
    is_my_threadãŒFalseã®å ´åˆã¯ã€è¿”ä¿¡ã‚’ç”Ÿæˆã›ãšã«ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚
    """
    logging.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_csv}")
    
    try:
        df = pd.read_csv(input_csv)
    except FileNotFoundError:
        logging.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}")
        return None

    # is_my_thread ãŒãƒ–ãƒ¼ãƒ«å€¤ã§ãªã„å¯èƒ½æ€§ã‚’è€ƒæ…®ã—ã¦å¤‰æ›
    if 'is_my_thread' in df.columns:
        df['is_my_thread'] = df['is_my_thread'].apply(lambda x: str(x).lower() == 'true')
    else:
        df['is_my_thread'] = False
        logging.warning("'is_my_thread' åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€ã™ã¹ã¦ä»–äººã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¸ã®ãƒªãƒ—ãƒ©ã‚¤ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã§ä»¶æ•°ã‚’åˆ¶é™
    df_to_process = df.head(limit).copy() if limit is not None else df.copy()
    if limit is not None:
        logging.info(f"å‡¦ç†ä»¶æ•°ã‚’ {limit} ä»¶ã«åˆ¶é™ã—ã¾ã™ã€‚")

    logging.info(f"åˆè¨ˆ {len(df_to_process)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

    # is_my_thread ã«åŸºã¥ã„ã¦è¿”ä¿¡ã‚’ç”Ÿæˆ
    generated_replies = []
    for index, row in df_to_process.iterrows():
        if row['is_my_thread']:
            logging.info(f"è¿”ä¿¡ã‚’ç”Ÿæˆä¸­... (å¯¾è±¡UserID: {row['UserID']}, is_my_thread: True)")
            generated_replies.append(generate_reply_for_row(row))
        else:
            logging.info(f"è¿”ä¿¡ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (å¯¾è±¡UserID: {row['UserID']}, is_my_thread: False)")
            generated_replies.append("") # è¿”ä¿¡ã‚’ç”Ÿæˆã—ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—

    # ç”Ÿæˆã—ãŸè¿”ä¿¡ã‚’æ–°ã—ã„åˆ—ã¨ã—ã¦è¿½åŠ 
    df_to_process['generated_reply'] = generated_replies
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
    base_name = os.path.basename(input_csv)
    name_part = base_name.replace('priority_replies_rechecked_', '')
    output_filename = f"generated_replies_{name_part}"
    output_path = os.path.join("output", output_filename)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("output", exist_ok=True)

    # çµæœã‚’CSVã«ä¿å­˜
    df_to_process.to_csv(output_path, index=False, encoding='utf-8-sig', lineterminator='\n')

    logging.info(f"è¿”ä¿¡ç”Ÿæˆå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_path} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    return output_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='AIã«ã‚ˆã‚‹è¿”ä¿¡ã‚’ç”Ÿæˆã—ã€CSVã«å‡ºåŠ›ã—ã¾ã™ã€‚')
    parser.add_argument('input_csv', type=str, help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ä¾‹: output/priority_replies_rechecked_YYYYMMDD_HHMMSS.csv)')
    parser.add_argument('--limit', type=int, help='å‡¦ç†ã™ã‚‹ãƒªãƒ—ãƒ©ã‚¤ã®æœ€å¤§ä»¶æ•°ã€‚')
    
    args = parser.parse_args()
    
    main_process(args.input_csv, args.limit) 