import google.generativeai as genai
import random
import pandas as pd
import argparse
import os
import logging
import emoji
import re
from .config import GEMINI_API_KEY, MAYA_PERSONALITY_PROMPT, THANK_YOU_PHRASES
from .db import get_user_preference

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Gemini APIã‚­ãƒ¼ã‚’è¨­å®š
genai.configure(api_key=GEMINI_API_KEY)

def is_emoji_only(text: str) -> bool:
    """
    æ–‡å­—åˆ—ãŒçµµæ–‡å­—ã€ç©ºç™½ã€å¥èª­ç‚¹ã®ã¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    """
    if not text or not isinstance(text, str):
        return False
    # çµµæ–‡å­—ã€å¥èª­ç‚¹ã€ç©ºç™½ä»¥å¤–ã®æ–‡å­—ã‚’ã™ã¹ã¦å–ã‚Šé™¤ã
    text_without_symbols = re.sub(r'[^\w\s]', '', text) # ã¾ãšå¥èª­ç‚¹ã‚’å‰Šé™¤
    demojized_text = emoji.demojize(text_without_symbols).strip()

    # æ®‹ã£ãŸæ–‡å­—åˆ—ãŒç©ºã‹ã€ã‚³ãƒ­ãƒ³ã§å›²ã¾ã‚ŒãŸçµµæ–‡å­—ã‚³ãƒ¼ãƒ‰ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯
    # (ä¾‹: ":heart:")
    if not demojized_text:
        return True # ç©ºç™½ã‚„å¥èª­ç‚¹ã®ã¿ã ã£ãŸå ´åˆã‚‚Trueã¨ã¿ãªã™
    
    # ã™ã¹ã¦ã®å˜èªãŒçµµæ–‡å­—ã‚³ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯
    return all(re.fullmatch(r':[a-zA-Z0-9_+-]+:', word) for word in demojized_text.split())

def generate_reply_for_row(row: pd.Series, original_tweet_content: str = None) -> str:
    """
    DataFrameã®è¡Œãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€AIãŒç”Ÿæˆã—ãŸå¿œç­”æ–‡ã‚’è¿”ã—ã¾ã™ã€‚
    
    Args:
        row (pd.Series): è¿”ä¿¡ã‚’ç”Ÿæˆã™ã‚‹å¯¾è±¡ã®ãƒªãƒ—ãƒ©ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¡Œã€‚
        original_tweet_content (str): Mayaã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”æ–‡ã€‚
    """
    reply_text = row['contents']
    replier_id = row['UserID']
    lang = row.get('lang', 'und') # langåˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã«å‚™ãˆã‚‹

    # ãƒªãƒ—ãƒ©ã‚¤ãŒçµµæ–‡å­—ã®ã¿ã®å ´åˆã®å‡¦ç†
    if is_emoji_only(reply_text):
        logging.info(f"ãƒªãƒ—ãƒ©ã‚¤ã¯çµµæ–‡å­—ã®ã¿ã§ã™ (è¨€èª: {lang})ã€‚å›ºå®šã®æ„Ÿè¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚")
        # è¨€èªã«å¯¾å¿œã™ã‚‹æ„Ÿè¬ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        thank_you_list = THANK_YOU_PHRASES.get(lang, THANK_YOU_PHRASES.get("und"))
        if thank_you_list and isinstance(thank_you_list, list):
            return random.choice(thank_you_list)
        else: # ä¸‡ãŒä¸€ã€è©²å½“ã™ã‚‹ã‚­ãƒ¼ãŒãªã‹ã£ãŸå ´åˆã‚„ãƒªã‚¹ãƒˆã§ãªã„å ´åˆ
            return "â¤ï¸"

    # jaä»¥å¤–ã®è¨€èªã®å ´åˆã€å›ºå®šã®ã€Œã‚ã‚ŠãŒã¨ã†ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ (çµµæ–‡å­—ã®ã¿ã§ãªã„å ´åˆ)
    if lang != "ja":
        if lang in THANK_YOU_PHRASES and isinstance(THANK_YOU_PHRASES[lang], list):
            return random.choice(THANK_YOU_PHRASES[lang])
        else:
            return "â¤ï¸"

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‘¼ã³åã‚’å–å¾—
    nickname = None
    if replier_id:
        preference = get_user_preference(replier_id.lower())
        if preference:
            nickname = preference[0]  # nicknameã¯ã‚¿ãƒ—ãƒ«ã®æœ€åˆã®è¦ç´ 
            logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID '{replier_id}' ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ  '{nickname}' ã‚’DBã‹ã‚‰å–å¾—ã—ã¾ã—ãŸã€‚")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    prompt_parts = []
    if nickname:
        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆï¼šMayaã®ãƒšãƒ«ã‚½ãƒŠã§ã€è¿”ä¿¡æœ¬æ–‡ã®ã¿ã‚’ç”Ÿæˆã•ã›ã‚‹
        prompt_parts.extend([
            MAYA_PERSONALITY_PROMPT,
            f"ã‚ãªãŸã¯ä»Šã‹ã‚‰ã€Œ{nickname}ã€ã•ã‚“ã¸è¿”ä¿¡ã—ã¾ã™ã€‚",
            "ä»¥ä¸‹ã®ãƒªãƒ—ãƒ©ã‚¤ã«å¯¾ã—ã¦ã€è¨­å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠã«åŸºã¥ã„ã¦è‡ªç„¶ãªæ—¥æœ¬èªã®è¿”ä¿¡ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
        ])
        if original_tweet_content:
            prompt_parts.append(f'ç§ã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ï¼š"{original_tweet_content}"')
        prompt_parts.append(f'ç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ï¼š"{reply_text}"')
        prompt_parts.append(
            "ã€é‡è¦äº‹é …ã€‘\n"
            "1. è¿”ä¿¡ã®æ–‡ç« ã«ã€ç›¸æ‰‹ã®å‘¼ã³ã‹ã‘ï¼ˆã€Œã€‡ã€‡ã•ã‚“ã€ãªã©ï¼‰ã¯çµ¶å¯¾ã«å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚\n"
            "2. ç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ã‚’è¸ã¾ãˆãŸè‡ªç„¶ãªè¿”ç­”ï¼ˆ15ã€œ35æ–‡å­—å‰å¾Œï¼‰ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚\n"
            "3. èªå°¾ã«ã¯å¿…ãšâ¤ï¸ã‹ğŸ©·ã‚’ä¸€ã¤ã ã‘ä»˜ã‘ã¦ãã ã•ã„ã€‚\n"
            "4. çµµæ–‡å­—ã¯è¨€è‘‰ã®é€”ä¸­ã«å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚"
        )
    else:
        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒãªã„å ´åˆï¼šMayaã®ãƒšãƒ«ã‚½ãƒŠã§ã€ã§ã‚‚çŸ­ã‚ã«
        logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID '{replier_id}' ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Mayaã®ãƒšãƒ«ã‚½ãƒŠã§çŸ­ã‚ã®è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
        prompt_parts.extend([
            MAYA_PERSONALITY_PROMPT,
            "ä»¥ä¸‹ã®ãƒªãƒ—ãƒ©ã‚¤ã«å¯¾ã—ã¦ã€è¨­å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠã«åŸºã¥ã„ã¦è‡ªç„¶ã§çŸ­ã„æ—¥æœ¬èªã®è¿”ä¿¡ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
            f'ç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ï¼š"{reply_text}"',
            "ã€é‡è¦äº‹é …ã€‘",
            "- ç›¸æ‰‹ã¸ã®å‘¼ã³ã‹ã‘ï¼ˆã€Œã€‡ã€‡ã•ã‚“ã€ãªã©ï¼‰ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚",
            "- è¿”ä¿¡ã¯éå¸¸ã«çŸ­ãã€è¦ç‚¹ã ã‘ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼šã€Œã‚ã‚ŠãŒã¨ã†ï¼å¬‰ã—ã„ãªâ¤ï¸ã€ã€Œãã£ã‹ãã£ã‹ã€ãŠç–²ã‚Œæ§˜ï¼ğŸ©·ã€ï¼‰",
            "- èªå°¾ã«ã¯å¿…ãšâ¤ï¸ã‹ğŸ©·ã‚’ä¸€ã¤ã ã‘ä»˜ã‘ã¦ãã ã•ã„ã€‚"
        ])

    prompt = "\n".join(prompt_parts)

    try:
        # Gemini APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”æ–‡ã‚’ç”Ÿæˆ
        model = genai.GenerativeModel('gemini-1.5-flash') # ã¾ãŸã¯ 'gemini-pro'
        response = model.generate_content(prompt)
        
        generated_content = response.text.strip()
        
        # AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­ã«ä»˜ã„ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã€Œ@...ã€ã‚’å‰Šé™¤
        generated_content = re.sub(r'^@\S+\s*', '', generated_content)

        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã€AIãŒç”Ÿæˆã—ãŸæœ¬æ–‡ã®å…ˆé ­ã«ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°å‰Šé™¤
        if nickname:
            # æ­£è¦è¡¨ç¾ã§ã€å…ˆé ­ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¨ãã‚Œã«ç¶šãå¯èƒ½æ€§ã®ã‚ã‚‹å¥èª­ç‚¹ã‚„ç©ºç™½ã‚’å‰Šé™¤
            escaped_nickname = re.escape(nickname)
            generated_content = re.sub(f'^{escaped_nickname}[ã€, ]*', '', generated_content).lstrip()

        # AIãŒèªå°¾ã®çµµæ–‡å­—ã‚’ä»˜ã‘å¿˜ã‚ŒãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if lang == "ja" and not generated_content.endswith(("â¤ï¸", "ğŸ©·")):
            generated_content += random.choice(["â¤ï¸", "ğŸ©·"])
            
        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯ã€å…ˆé ­ã«å‘¼ã³ã‹ã‘ã¨æ”¹è¡Œã‚’è¿½åŠ 
        if nickname:
            return f"{nickname}\n{generated_content}"
        
        return generated_content
    except Exception as e:
        logging.error(f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return ""


def main_process(input_csv: str, limit: int = None):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¸€ä»¶ãšã¤ä¿å­˜ã—ã¾ã™ã€‚
    """
    logging.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_csv}")
    
    try:
        df = pd.read_csv(input_csv)
    except FileNotFoundError:
        logging.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}")
        return None

    # is_my_threadãŒTrueã®è¡Œã«çµã‚Šè¾¼ã‚€
    my_thread_replies = df[df['is_my_thread'] == True].copy()
    
    if my_thread_replies.empty:
        logging.info("è‡ªåˆ†ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¸ã®è¿”ä¿¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return None

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã§ä»¶æ•°ã‚’åˆ¶é™
    if limit is not None:
        logging.info(f"å‡¦ç†ä»¶æ•°ã‚’ {limit} ä»¶ã«åˆ¶é™ã—ã¾ã™ã€‚")
        my_thread_replies = my_thread_replies.head(limit)

    logging.info(f"è‡ªåˆ†ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¸ã®è¿”ä¿¡ {len(my_thread_replies)} ä»¶ã«å¯¾ã—ã¦è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
    base_name = os.path.basename(input_csv)
    # priority_replies_rechecked_ ã‚’ generated_replies_ ã«ç½®æ›
    name_part = base_name.replace('priority_replies_rechecked_', '')
    output_filename = f"generated_replies_{name_part}"
    output_path = os.path.join("output", output_filename)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("output", exist_ok=True)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ (ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿)
    output_df_columns = list(my_thread_replies.columns) + ['generated_reply']
    pd.DataFrame(columns=output_df_columns).to_csv(output_path, index=False, encoding='utf-8-sig')

    # ä¸€ä»¶ãšã¤å‡¦ç†ã—ã¦è¿½è¨˜
    for index, row in my_thread_replies.iterrows():
        logging.info(f"è¿”ä¿¡ã‚’ç”Ÿæˆä¸­... (å¯¾è±¡UserID: {row['UserID']})")
        
        generated_reply = generate_reply_for_row(row)
        
        # å…ƒã®è¡Œã«ç”Ÿæˆã—ãŸè¿”ä¿¡ã‚’è¿½åŠ 
        row_with_reply = row.to_dict()
        row_with_reply['generated_reply'] = generated_reply
        
        # DataFrameã«å¤‰æ›ã—ã¦CSVã«è¿½è¨˜
        pd.DataFrame([row_with_reply]).to_csv(output_path, mode='a', header=False, index=False, encoding='utf-8-sig')
        logging.info(f" -> ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ã‚’ {output_path} ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚")
        
    logging.info(f"è¿”ä¿¡ç”Ÿæˆå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_path} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    return output_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='AIã«ã‚ˆã‚‹è¿”ä¿¡ã‚’ç”Ÿæˆã—ã€CSVã«å‡ºåŠ›ã—ã¾ã™ã€‚')
    parser.add_argument('input_csv', type=str, help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ä¾‹: output/priority_replies_rechecked_YYYYMMDD_HHMMSS.csv)')
    parser.add_argument('--limit', type=int, help='å‡¦ç†ã™ã‚‹ãƒªãƒ—ãƒ©ã‚¤ã®æœ€å¤§ä»¶æ•°ã€‚')
    
    args = parser.parse_args()
    
    main_process(args.input_csv, args.limit) 