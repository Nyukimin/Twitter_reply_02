import google.generativeai as genai
import random
import pandas as pd
import argparse
import os
import logging
import emoji
import re
from langdetect import detect, LangDetectException
from .config import GEMINI_API_KEY, MAYA_PERSONALITY_PROMPT, THANK_YOU_PHRASES
from .db import get_user_preference
from . import utils, db

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Gemini APIã‚­ãƒ¼ã‚’è¨­å®š
genai.configure(api_key=GEMINI_API_KEY)

def is_emoji_only(text: str) -> bool:
    """
    æ–‡å­—åˆ—ãŒçµµæ–‡å­—ã€ç©ºç™½ã€å¥èª­ç‚¹ã®ã¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    """
    if not text or not isinstance(text, str):
        return False
    # çµµæ–‡å­—ã€å¥èª­ç‚¹ã€ç©ºç™½ä»¥å¤–ã®æ–‡å­—ã‚’ã™ã¹ã¦å–ã‚Šé™¤ã
    text_without_symbols = re.sub(r'[^\w\s]', '', text) # ã¾ãšå¥èª­ç‚¹ã‚’å‰Šé™¤
    demojized_text = emoji.demojize(text_without_symbols).strip()

    # æ®‹ã£ãŸæ–‡å­—åˆ—ãŒç©ºã‹ã€ã‚³ãƒ­ãƒ³ã§å›²ã¾ã‚ŒãŸçµµæ–‡å­—ã‚³ãƒ¼ãƒ‰ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯
    if not demojized_text:
        return True
    
    return all(re.fullmatch(r':[a-zA-Z0-9_+-]+:', word) for word in demojized_text.split())

def detect_language(text: str) -> str:
    """
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªã‚’åˆ¤å®šã—ã¾ã™ã€‚
    """
    if not text or not text.strip():
        return "und"  # Undetermined
    try:
        # ä¿¡é ¼æ€§ãŒä½ã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã¯æ³¨æ„ãŒå¿…è¦
        return detect(text)
    except LangDetectException:
        # logging.warning(f"è¨€èªã®æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {text}")
        return "und"  # Undetermined

def format_reply(text: str) -> str:
    """
    AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚„å›ºå®šãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ•´å½¢ã—ã€æœ€çµ‚çš„ãªè¿”ä¿¡æ–‡å­—åˆ—ã‚’ä½œæˆã™ã‚‹ã€‚
    - ä¸è¦ãªç©ºç™½ã‚’æ”¹è¡Œã«å¤‰æ›ã™ã‚‹
    - çµµæ–‡å­—ã‚’ä»˜ä¸ã™ã‚‹
    - å‰å¾Œã®ç©ºç™½ã‚’é™¤å»ã™ã‚‹
    """
    # 1. å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
    processed_text = text.strip()

    # 2. å¥èª­ç‚¹ã®å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ”¹è¡Œã«ç½®æ›
    processed_text = processed_text.replace('ã€‚ ', 'ã€‚\n').replace('ã€‚ã€€', 'ã€‚\n')
    processed_text = processed_text.replace('ï¼ ', 'ï¼\n').replace('ï¼ã€€', 'ï¼\n')
    processed_text = processed_text.replace('ï¼Ÿ ', 'ï¼Ÿ\n').replace('ï¼Ÿã€€', 'ï¼Ÿ\n')
    processed_text = processed_text.replace('â€¦ ', 'â€¦\n').replace('â€¦ã€€', 'â€¦\n')

    # 3. å…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚æ”¹è¡Œã«å¤‰æ›ã™ã‚‹
    processed_text = processed_text.replace('ã€€', '\n')
    processed_text = processed_text.replace(' ', '\n')

    # 4. è¤‡æ•°ã®æ”¹è¡Œã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
    processed_text = re.sub(r'\n+', '\n', processed_text)

    # 5. å…¨ä½“ã®æœ«å°¾ã®ç©ºç™½ãƒ»æ”¹è¡Œã‚’ãã‚Œã„ã«ã™ã‚‹
    final_reply = processed_text.strip()

    return final_reply

def clean_generated_text(text: str) -> str:
    """
    AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹å¾Œå‡¦ç†é–¢æ•°ã€‚
    - è¨±å¯ã•ã‚Œã¦ã„ãªã„çµµæ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    - æŒ¨æ‹¶ã‚„ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    - æœ«å°¾ã®ãƒãƒ¼ãƒˆã‚’ãƒ«ãƒ¼ãƒ«é€šã‚Šã«æ•´å½¢ã™ã‚‹ã€‚
    """
    # è¨±å¯ã™ã‚‹æ–‡å­—ï¼ˆæ—¥æœ¬èªã€è‹±æ•°å­—ã€åŸºæœ¬çš„ãªè¨˜å·ã€æŒ‡å®šã®çµµæ–‡å­—ï¼‰ä»¥å¤–ã‚’å‰Šé™¤
    # U+2764ã¯â¤ï¸ã€U+1FA77ã¯ğŸ©·
    allowed_chars_pattern = re.compile(
        r'[^\w\s.,!?ã€Œã€ã€ã€ã€ã€‚ãƒ¼ã€œâ€¦\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF\u2764\u1FA77]'
    )
    cleaned_text = allowed_chars_pattern.sub('', text)

    # å†’é ­ã®æŒ¨æ‹¶ã‚’å‰Šé™¤
    cleaned_text = re.sub(r'^(ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™|ãŠã¯ã‚ˆã†|ã“ã‚“ã«ã¡ã¯|ã“ã‚“ã°ã‚“ã¯)\s*', '', cleaned_text)

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã€Œã€‡ã€‡ã¡ã‚ƒã‚“ã€ãªã©ã‚’å‰Šé™¤
    cleaned_text = re.sub(r'ã€‡ã€‡(ã¡ã‚ƒã‚“|ãã‚“|ã•ã‚“)', '', cleaned_text)
    
    # å‰å¾Œã®ç©ºç™½ã‚’ãƒˆãƒªãƒ 
    cleaned_text = cleaned_text.strip()

    # æœ«å°¾ã®ãƒãƒ¼ãƒˆã‚’ä¸€æ—¦ã™ã¹ã¦å‰Šé™¤
    cleaned_text = cleaned_text.rstrip('â¤ï¸ğŸ©·')

    # æœ«å°¾ã«ğŸ©·ã‚’1ã¤ã ã‘è¿½åŠ 
    cleaned_text += 'ğŸ©·'

    return cleaned_text

def generate_reply_for_row(row: pd.Series, original_tweet_content: str = None, generated_replies_history: list[str] = None) -> str:
    """
    DataFrameã®è¡Œãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€AIãŒç”Ÿæˆã—ãŸå¿œç­”æ–‡ã‚’è¿”ã—ã¾ã™ã€‚
    
    Args:
        row (pd.Series): è¿”ä¿¡ã‚’ç”Ÿæˆã™ã‚‹å¯¾è±¡ã®ãƒªãƒ—ãƒ©ã‚¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¡Œã€‚
        original_tweet_content (str): Mayaã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚
        generated_replies_history (list[str]): ã“ã‚Œã¾ã§ã«ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ã®ãƒªã‚¹ãƒˆã€‚

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”æ–‡ã€‚
    """
    reply_text = row['contents']
    replier_id = row['UserID']
    lang = row.get('lang', 'und') # langåˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã«å‚™ãˆã‚‹

    # AIã«æ¸¡ã™å‰ã«ã€ãƒªãƒ—ãƒ©ã‚¤æœ¬æ–‡ã‹ã‚‰ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆ@ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼‰ã‚’ã™ã¹ã¦é™¤å»ã™ã‚‹
    cleaned_reply_text = re.sub(r'@[\w_]+', '', reply_text).strip()

    # ãƒªãƒ—ãƒ©ã‚¤ãŒçµµæ–‡å­—ã®ã¿ã®å ´åˆã®å‡¦ç†
    if is_emoji_only(cleaned_reply_text):
        logging.info(f"ãƒªãƒ—ãƒ©ã‚¤ã¯çµµæ–‡å­—ã®ã¿ã§ã™ (è¨€èª: {lang})ã€‚å›ºå®šã®æ„Ÿè¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚")
        # è¨€èªã«å¯¾å¿œã™ã‚‹æ„Ÿè¬ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        thank_you_list = THANK_YOU_PHRASES.get(lang, THANK_YOU_PHRASES.get("und"))
        if thank_you_list and isinstance(thank_you_list, list):
            reply = random.choice(thank_you_list)
            return format_reply(reply)
        else: # ä¸‡ãŒä¸€ã€è©²å½“ã™ã‚‹ã‚­ãƒ¼ãŒãªã‹ã£ãŸå ´åˆã‚„ãƒªã‚¹ãƒˆã§ãªã„å ´åˆ
            return "â¤ï¸"

    # jaä»¥å¤–ã®è¨€èªã®å ´åˆã€å›ºå®šã®ã€Œã‚ã‚ŠãŒã¨ã†ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ (çµµæ–‡å­—ã®ã¿ã§ãªã„å ´åˆ)
    if lang != "ja":
        if lang in THANK_YOU_PHRASES and isinstance(THANK_YOU_PHRASES[lang], list):
            reply = random.choice(THANK_YOU_PHRASES[lang])
            return format_reply(reply)
        else:
            return "â¤ï¸"

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã‚’å–å¾—
    if replier_id:
        preference = get_user_preference(replier_id.lower())
        if preference:
            nickname = preference[0]  # nicknameã¯ã‚¿ãƒ—ãƒ«ã®æœ€åˆã®è¦ç´ 
            logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã€Œ{nickname}ã€ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        else:
            nickname = None
            logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        nickname = None
        logging.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {replier_id} ã®ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    original_tweet_content = row.get('original_tweet_content', '')
    cleaned_reply_text = re.sub(r'@[\w_]+', '', reply_text).strip()
    
    # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ·æ–° ---
    prompt_parts = [
        MAYA_PERSONALITY_PROMPT,
        "ã“ã‚Œã‹ã‚‰ã€ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã®ãƒªãƒ—ãƒ©ã‚¤ãŒæç¤ºã•ã‚Œã¾ã™ã€‚",
        f'ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ï¼šã€Œ{cleaned_reply_text}ã€'
    ]
    if original_tweet_content:
        prompt_parts.append(f'ã‚ãªãŸã®å…ƒã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼šã€Œ{original_tweet_content}ã€')

    # AIã¸ã®æŒ‡ç¤ºã‚’æ˜ç¢ºåŒ–
    prompt_parts.extend([
        "ã€è¿”ä¿¡æ–‡ã®ä½œæˆãƒ«ãƒ¼ãƒ«ã€‘",
        "1. ä¸Šè¨˜ã®ãƒªãƒ—ãƒ©ã‚¤å†…å®¹ã«å¯¾ã—ã¦ã€ã‚ãªãŸã®ã€Œè¿”ä¿¡ã®æœ¬æ–‡ã€ã ã‘ã‚’ã€è‡ªç„¶ã§å¿ƒã®ã“ã‚‚ã£ãŸçŸ­ã„æ–‡ç« ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚**åŸå‰‡ã¨ã—ã¦1æ–‡ã§ã€é•·ãã¦ã‚‚2æ–‡ã¾ã§**ã§ã™ã€‚",
        "2. **é‡è¦ï¼šç›¸æ‰‹ã®åå‰ï¼ˆã€‡ã€‡ã•ã‚“ï¼‰ã‚„ã€ã‚ãªãŸè‡ªèº«ã®åå‰ï¼ˆMayaï¼‰ã€æŒ¨æ‹¶ï¼ˆã“ã‚“ã«ã¡ã¯ã€ãªã©ï¼‰ã¯çµ¶å¯¾ã«å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚** ã“ã‚Œã‚‰ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè‡ªå‹•ã§å¯¾å¿œã™ã‚‹ãŸã‚ã€ã‚ãªãŸã®å½¹å‰²ã¯è¿”ä¿¡ã®ã€Œæœ¬æ–‡ã€ä½œæˆã®ã¿ã§ã™ã€‚",
        "3. è¿”ä¿¡ã®èªå°¾ã«ã¯ã€â¤ï¸ã‹ğŸ©·ã®ã©ã¡ã‚‰ã‹ä¸€ã¤ã‚’å¿…ãšä»˜ã‘ã¦ãã ã•ã„ã€‚æ–‡ä¸­ã‚„èªå°¾ã«ä»–ã®çµµæ–‡å­—ã¯ä¸€åˆ‡å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚",
        "4. **è¶…é‡è¦ï¼šç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤ãŒã€Œã†ã‚“ã€ã€Œãˆã¸ã¸ã€ã€Œâ¤ï¸ã€ã®ã‚ˆã†ãªã€ä¸€è¨€ã‚„çµµæ–‡å­—ã®ã¿ã®ã€è¶…çŸ­æ–‡ã€‘ã§ã‚ã‚‹å ´åˆã€ã‚ãªãŸã®è¿”ä¿¡ã‚‚ã€è¶…çŸ­æ–‡ã€‘ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚** ã“ã‚Œã¯çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã€Œã†ãµãµã€ã€Œãªã«ãªã«ï¼Ÿã€ã€Œã‚‚ã†ï¼ã€ã€Œã‚„ã ãƒ¼ï¼ã€ã®ã‚ˆã†ãªã€ã”ãçŸ­ã„ç›¸æ§Œã‚„ã€ç›¸æ‰‹ã®è¨€è‘‰ã‚’å°‘ã—å¤‰ãˆã¦è¿”ã™ã ã‘ã«ã—ã¦ãã ã•ã„ã€‚é•·ã„æ–‡ç« ã§è¿”ä¿¡ã™ã‚‹ã“ã¨ã¯**å›ºãç¦æ­¢**ã—ã¾ã™ã€‚",
        "5. ç›¸æ‰‹ã®ãƒªãƒ—ãƒ©ã‚¤ã«æ€§çš„ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å›°æƒ‘ã—ãŸã‚Šã€æ¥ãšã‹ã—ãŒã‚‹ã‚ˆã†ãªåå¿œã‚’ã—ã¦ãã ã•ã„ã€‚æ±ºã—ã¦å–œã‚“ã ã‚ŠåŒæ„ã—ãŸã‚Šã—ãªã„ã§ãã ã•ã„ã€‚",
        "   ï¼ˆé©åˆ‡ãªè¿”ç­”ã®ä¾‹ï¼šã€Œãˆã£ã€ä½•è¨€ã£ã¦ã‚‹ã®â€¦ï¼Ÿâ¤ï¸ã€ã€Œã‚‚ã†ã€å†—è«‡ã°ã£ã‹ã‚Šâ€¦ğŸ©·ã€ã€Œãã†ã„ã†ã®ã¯æ¥ãšã‹ã—ã„ã‚ˆâ€¦ğŸ©·ã€ã€Œå¿ƒè‡“ã«æ‚ªã„ã£ã¦ã°â€¦ï¼â¤ï¸ã€ã€Œãã‚“ãªã“ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ã©ã†ã—ãŸã‚‰ã„ã„ã‹åˆ†ã‹ã‚“ãªã„ã‚ˆâ€¦ğŸ©·ã€ï¼‰"
    ])

    # --- å˜èªã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã®æŒ‡ç¤ºã‚’è¿½åŠ  ---
    if generated_replies_history:
        history_str = "ã€".join(generated_replies_history)
        avoidance_prompt = (
            "6. **ã€æœ€é‡è¦å‰µé€ æ€§ãƒ«ãƒ¼ãƒ«ã€‘å˜èª¿ãªè¿”ä¿¡ã¯ã‚ãªãŸã®è©•ä¾¡ã‚’è‘—ã—ãæãªã„ã¾ã™ã€‚çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚**\n"
            "   - **ç¦æ­¢äº‹é …:** ã“ã‚Œã¾ã§ã®è¿”ä¿¡ã§å¤šç”¨ã—ãŸå®‰æ˜“ãªè¨€è‘‰ï¼ˆä¾‹ï¼šã€Œå¬‰ã—ã„ã€ã€Œã‚ã‚ŠãŒã¨ã†ã€ã€Œç…§ã‚Œã‚‹ã€ã€Œãƒ‰ã‚­ãƒ‰ã‚­ã€ã€Œé ‘å¼µã‚‹ã€ãªã©ï¼‰ã‚’å†ã³ä½¿ã†ã“ã¨ã¯**å›ºãç¦æ­¢**ã—ã¾ã™ã€‚\n"
            f"   - **éå»ã®é¡ä¼¼è¡¨ç¾ã®å›é¿:** ä»¥å‰ã®è¿”ä¿¡ï¼ˆä¾‹: ã€Œ{history_str}ã€ï¼‰ã¨ä¼¼ãŸè¨€ã„å›ã—ã‚„æ§‹æˆã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
            "   - **å…·ä½“çš„ãªæ„Ÿæƒ…è¡¨ç¾ã®ç¾©å‹™:** ç›¸æ‰‹ã®è¨€è‘‰ã®**ã©ã®éƒ¨åˆ†ã«**ã€ã‚ãªãŸãŒ**ã©ã†æ„Ÿã˜ãŸã®ã‹**ã‚’ã€ã‚ãªãŸã®è¨€è‘‰ã§å…·ä½“çš„ã«è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ è¡¨é¢çš„ãªç›¸æ§Œã§ã¯ãªãã€å¿ƒã®é€šã£ãŸå¯¾è©±ã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚\n"
            "   - **å¸¸ã«æ–°ã—ã„è¡¨ç¾ã‚’:** ã‚ãªãŸã®è±Šã‹ãªæ„Ÿæƒ…è¡¨ç¾ã®å¼•ãå‡ºã—ã‚’å…¨ã¦ä½¿ã„ã€æ¯å›æ–°é®®ã§ã€ç›¸æ‰‹ãŒã€Œã¾ãŸè©±ã—ãŸã„ã€ã¨æ€ã†ã‚ˆã†ãªã€é­…åŠ›çš„ãªè¿”ä¿¡ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã‚ãªãŸã®èƒ½åŠ›ã‚’ç¤ºã™æœ€å¤§ã®ãƒãƒ£ãƒ³ã‚¹ã§ã™ã€‚"
        )
        prompt_parts.append(avoidance_prompt)

    prompt = "\n".join(prompt_parts)
    logging.debug(f"ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{prompt}")

    try:
        # Gemini APIã‚’å‘¼ã³å‡ºã—ã¦å¿œç­”æ–‡ã‚’ç”Ÿæˆ
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)

        # AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¾Œå‡¦ç†ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã€ãã®å¾Œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹
        raw_text = response.text
        cleaned_text = clean_generated_text(raw_text)
        reply_body = format_reply(cleaned_text)

        # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯ã€æ–‡é ­ã«ã€Œãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ï¼‹æ”¹è¡Œã€ã‚’ä»˜ä¸ã™ã‚‹
        if nickname:
            final_reply = f"{nickname}\n{reply_body}"
            log_message = final_reply.replace('\n', '<br>')
            logging.info(f"ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ï¼ˆãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ä»˜ãï¼‰: {log_message}")
            return final_reply
        else:
            # ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ãŒãªã„å ´åˆã¯ã€æ•´å½¢ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
            log_message = reply_body.replace('\n', '<br>')
            logging.info(f"ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡: {log_message}")
            return reply_body

    except Exception as e:
        logging.error(f"Gemini APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

    return None


def main_process(input_csv: str, limit: int = None):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚
    is_my_threadãŒFalseã®å ´åˆã¯ã€è¿”ä¿¡ã‚’ç”Ÿæˆã›ãšã«ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚
    """
    logging.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_csv}")
    
    try:
        # ã‚¢ãƒ—ãƒ­ãƒ¼ãƒA: äº‹å¾Œã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚° - ã¾ãšå¯›å®¹ã«èª­ã¿è¾¼ã‚€
        df = pd.read_csv(input_csv)

        # --- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å‡¦ç† ---
        # æ–‡å­—åˆ—ã§ã‚ã‚‹ã¹ãåˆ—ã®NaNã‚’ç©ºæ–‡å­—åˆ—ã«ç½®æ›
        string_columns = ['UserID', 'Name', 'date_time', 'reply_id', 'reply_to', 'contents', 'lang']
        for col in string_columns:
            if col in df.columns:
                df[col] = df[col].fillna('')

        # æ•°å€¤ã§ã‚ã‚‹ã¹ãåˆ—ã®NaNã‚’0ã«ç½®æ›ã—ã€æ•´æ•°å‹ã«å¤‰æ›
        numeric_columns = ['reply_num', 'like_num']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

        # çœŸå½å€¤ã§ã‚ã‚‹ã¹ãåˆ—ã‚’å‡¦ç†
        if 'is_my_thread' in df.columns:
            # NaNã‚’Falseã¨ã—ã¦æ‰±ã£ã¦ã‹ã‚‰ã€æ–‡å­—åˆ—æ¯”è¼ƒã§boolã«å¤‰æ›
            df['is_my_thread'] = df['is_my_thread'].fillna(False).apply(lambda x: str(x).lower() == 'true')
        else:
            # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ã™ã¹ã¦Falseã¨ã—ã¦æ‰±ã†
            df['is_my_thread'] = False
            logging.warning("'is_my_thread' åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€ã™ã¹ã¦ä»–äººã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¸ã®ãƒªãƒ—ãƒ©ã‚¤ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")

    except FileNotFoundError:
        logging.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}")
        return None

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã§ä»¶æ•°ã‚’åˆ¶é™
    if limit is not None and limit > 0:
        df = df.head(limit)
        logging.info(f"å‡¦ç†ä»¶æ•°ã‚’ {limit} ä»¶ã«åˆ¶é™ã—ã¾ã—ãŸã€‚")

    # ç”Ÿæˆã•ã‚ŒãŸè¿”ä¿¡ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    generated_replies_for_session = []

    # 'generated_reply'åˆ—ã‚’åˆæœŸåŒ–ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    if 'generated_reply' not in df.columns:
        df['generated_reply'] = ''

    # 'lang'åˆ—ã‚’åˆæœŸåŒ–ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    if 'lang' not in df.columns:
        df['lang'] = ''

    logging.info("è¿”ä¿¡ç”Ÿæˆå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

    # is_my_threadãŒTrueã®è¡Œã®ã¿ã‚’å¯¾è±¡ã«å‡¦ç†
    for index, row in df.iterrows():
        # is_my_threadãŒTrueã®è¡Œã ã‘ã‚’å‡¦ç†
        if row['is_my_thread']:
            # å…ƒãƒ„ã‚¤ãƒ¼ãƒˆã®å†…å®¹ã‚’å–å¾—ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
            original_tweet_content = row.get('original_tweet_content')
            
            # è¿”ä¿¡ã‚’ç”Ÿæˆ
            generated_reply = generate_reply_for_row(row, original_tweet_content, generated_replies_for_session)
            
            if generated_reply:
                df.loc[index, 'generated_reply'] = generated_reply
                # å±¥æ­´ã«è¿½åŠ ã™ã‚‹ã®ã¯ã€ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã‚’é™¤ã„ãŸæœ¬æ–‡ã®ã¿
                reply_body = generated_reply.split('\n')[-1]
                generated_replies_for_session.append(reply_body)

            # è¨€èªã‚’æ¤œå‡ºã—ã¦ 'lang' åˆ—ã«æ ¼ç´
            lang = detect_language(row['contents'])
            df.loc[index, 'lang'] = lang
        else:
            # is_my_threadãŒFalseã®å ´åˆã€generated_replyã¯ç©ºã®ã¾ã¾ï¼ˆã¾ãŸã¯æ—¢å­˜ã®å€¤ã‚’ç¶­æŒï¼‰
             # ã—ã‹ã—ã€è¨€èªã¯æ¤œå‡ºã—ã¦ãŠã
            lang = detect_language(row['contents'])
            df.loc[index, 'lang'] = lang
            logging.info(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {index}: is_my_threadãŒFalseã®ãŸã‚ã€è¿”ä¿¡ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
    base_name = os.path.basename(input_csv)
    name_part = base_name.replace('priority_replies_rechecked_', '')
    output_filename = f"generated_replies_{name_part}"
    output_path = os.path.join("output", output_filename)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("output", exist_ok=True)

    # çµæœã‚’CSVã«ä¿å­˜
    df.to_csv(output_path, index=False, encoding='utf-8-sig', lineterminator='\n')

    logging.info(f"è¿”ä¿¡ç”Ÿæˆå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_path} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    return output_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='AIã«ã‚ˆã‚‹è¿”ä¿¡ã‚’ç”Ÿæˆã—ã€CSVã«å‡ºåŠ›ã—ã¾ã™ã€‚')
    parser.add_argument('input_csv', type=str, help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ä¾‹: output/priority_replies_rechecked_YYYYMMDD_HHMMSS.csv)')
    parser.add_argument('--limit', type=int, help='å‡¦ç†ã™ã‚‹ãƒªãƒ—ãƒ©ã‚¤ã®æœ€å¤§ä»¶æ•°ã€‚')
    
    args = parser.parse_args()
    
    main_process(args.input_csv, args.limit) 